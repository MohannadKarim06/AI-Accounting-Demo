import streamlit as st
import pandas as pd
import requests
import base64
import json
import os
import time
import hashlib
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas

# =========================
# Page config
# =========================
st.set_page_config(
    page_title="Ù†Ø¸Ø§Ù… Ù…Ø­Ø§Ø³Ø¨Ø© Ø°ÙƒÙŠ",
    layout="wide"
)

# =========================
# Arabic RTL Styling
# =========================
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Cairo:wght@300;400;600;800&display=swap');

html, body, [class*="css"] {
    font-family: 'Cairo', sans-serif;
    direction: rtl;
    text-align: right;
}

.stDataFrame table {
    direction: rtl;
    text-align: right;
}

.stDataFrame th {
    text-align: right;
}
</style>
""", unsafe_allow_html=True)

# =========================
# Constants
# =========================
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
OPENROUTER_URL = "https://openrouter.ai/api/v1/chat/completions"
MODEL_VISION = "anthropic/claude-3.5-sonnet"

BASE_CACHE = "./data/cache"
DOC_CACHE = f"{BASE_CACHE}/documents"
QUERY_CACHE = f"{BASE_CACHE}/queries"
REPORT_CACHE = f"{BASE_CACHE}/reports"

for p in [DOC_CACHE, QUERY_CACHE, REPORT_CACHE]:
    os.makedirs(p, exist_ok=True)

# =========================
# Helpers
# =========================
def hash_bytes(data):
    return hashlib.sha256(data).hexdigest()

def call_llm(messages, max_tokens=1500):
    payload = {
        "model": MODEL_VISION,
        "messages": messages,
        "max_tokens": max_tokens,
        "temperature": 0.1
    }
    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json"
    }
    r = requests.post(OPENROUTER_URL, headers=headers, json=payload, timeout=60)
    r.raise_for_status()
    return r.json()["choices"][0]["message"]["content"]

# =========================
# Document Extraction
# =========================
def extract_document(file):
    raw = file.read()
    h = hash_bytes(raw)
    cache = f"{DOC_CACHE}/{h}.json"

    if os.path.exists(cache):
        time.sleep(1.5)
        return json.load(open(cache, encoding="utf-8"))

    prompt = """
Ø£Ù†Øª Ù…Ø­Ø§Ø³Ø¨ Ù…Ø­ØªØ±Ù.

Ø­Ù„Ù„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ ÙˆØ­Ø¯Ø¯ Ù‡Ù„ Ù‡Ùˆ:
- income (Ø¯Ø®Ù„)
- expense (Ù…ØµØ±ÙˆÙ)

Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©.
Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø©ØŒ Ø¶Ø¹ null ÙˆÙ„Ø§ ØªØ®Ù…Ù†.

Ø£Ø±Ø¬Ø¹ JSON ÙÙ‚Ø·:

{
 "transaction_type": "income Ø£Ùˆ expense",
 "document_type": null,
 "invoice_number": null,
 "date": null,
 "party_name": null,
 "category": null,
 "description": null,
 "subtotal": null,
 "tax_amount": null,
 "total_amount": null,
 "payment_method": null,
 "currency": "EGP",
 "confidence_score": 0.0
}
"""

    b64 = base64.b64encode(raw).decode()
    messages = [{
        "role": "user",
        "content": [
            {"type": "text", "text": prompt},
            {"type": "image_url", "image_url": {"url": f"data:{file.type};base64,{b64}"}}
        ]
    }]

    result = json.loads(call_llm(messages))
    result["source_document"] = file.name

    json.dump(result, open(cache, "w", encoding="utf-8"), ensure_ascii=False)
    return result

# =========================
# Semantic Query
# =========================
def semantic_query(df, question):
    prompt = f"""
Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:
{df.to_string(index=False)}

Ø§Ù„Ø³Ø¤Ø§Ù„:
{question}

Ø£Ø¬Ø¨ Ø¨ØµÙŠØºØ© JSON:
{{
 "answer_text": "",
 "answer_numeric": null,
 "rows": []
}}
"""
    return json.loads(call_llm([{"role": "user", "content": prompt}], 2000))

# =========================
# Report
# =========================
def generate_report(income_df, expense_df):
    total_income = income_df["Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø¨Ù„Øº"].sum()
    total_expense = expense_df["Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø¨Ù„Øº"].sum()
    net = total_income - total_expense

    return {
        "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†": "ØªÙ‚Ø±ÙŠØ± Ù…Ø§Ù„ÙŠ ØªØ­Ù„ÙŠÙ„ÙŠ",
        "Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¥ÙŠØ±Ø§Ø¯Ø§Øª": total_income,
        "Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…ØµØ±ÙˆÙØ§Øª": total_expense,
        "ØµØ§ÙÙŠ Ø§Ù„Ø±Ø¨Ø­": net,
        "Ø§Ù„Ù…Ù„Ø®Øµ": (
            "ÙŠØ¹Ø±Ø¶ Ù‡Ø°Ø§ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ù†Ø¸Ø±Ø© Ø´Ø§Ù…Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø§Ù„ÙŠ. "
            "ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ù…Ù† Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŒ "
            "Ù…Ù…Ø§ ÙŠØ³Ø§Ø¹Ø¯ Ø¹Ù„Ù‰ ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„ÙŠØ¯ÙˆÙŠØ© ÙˆØªØ­Ø³ÙŠÙ† Ø³Ø±Ø¹Ø© Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø±."
        )
    }

# =========================
# PDF Export
# =========================
def export_pdf(report):
    path = "/tmp/report.pdf"
    c = canvas.Canvas(path, pagesize=A4)
    text = c.beginText(450, 800)
    for k, v in report.items():
        text.textLine(f"{k}: {v}")
    c.drawText(text)
    c.save()
    return path

# =========================
# UI
# =========================
st.title("ğŸ“Š Ù†Ø¸Ø§Ù… Ù…Ø­Ø§Ø³Ø¨Ø© Ø°ÙƒÙŠ Ù…ØªÙƒØ§Ù…Ù„")

files = st.file_uploader("Ø§Ø±ÙØ¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª", accept_multiple_files=True)

income, expense = [], []

if files:
    for f in files:
        d = extract_document(f)
        if d["transaction_type"] == "income":
            income.append(d)
        else:
            expense.append(d)

if income or expense:
    income_df = pd.DataFrame(income)
    expense_df = pd.DataFrame(expense)

    rename_map = {
        "document_type": "Ù†ÙˆØ¹ Ø§Ù„Ù…Ø³ØªÙ†Ø¯",
        "invoice_number": "Ø±Ù‚Ù… Ø§Ù„ÙØ§ØªÙˆØ±Ø©",
        "date": "Ø§Ù„ØªØ§Ø±ÙŠØ®",
        "party_name": "Ø§Ù„Ø¹Ù…ÙŠÙ„ / Ø§Ù„Ù…ÙˆØ±Ø¯",
        "category": "Ø§Ù„ØªØµÙ†ÙŠÙ",
        "description": "Ø§Ù„ÙˆØµÙ",
        "subtotal": "Ù‚Ø¨Ù„ Ø§Ù„Ø¶Ø±ÙŠØ¨Ø©",
        "tax_amount": "Ø§Ù„Ø¶Ø±ÙŠØ¨Ø©",
        "total_amount": "Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø¨Ù„Øº",
        "payment_method": "Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¯ÙØ¹"
    }

    if not income_df.empty:
        st.subheader("ğŸ“ˆ Ø§Ù„Ø¥ÙŠØ±Ø§Ø¯Ø§Øª")
        st.dataframe(income_df.rename(columns=rename_map))

    if not expense_df.empty:
        st.subheader("ğŸ“‰ Ø§Ù„Ù…ØµØ±ÙˆÙØ§Øª")
        st.dataframe(expense_df.rename(columns=rename_map))

    q = st.text_input("Ø§Ø³Ø£Ù„ Ø¹Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    if q:
        res = semantic_query(pd.concat([income_df, expense_df]), q)
        st.markdown(f"**Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:** {res['answer_text']}")
        if res["rows"]:
            st.dataframe(pd.DataFrame(res["rows"]))

    if st.button("Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ±"):
        report = generate_report(
            income_df.rename(columns=rename_map),
            expense_df.rename(columns=rename_map)
        )
        st.json(report)
        with open(export_pdf(report), "rb") as f:
            st.download_button("ØªØ­Ù…ÙŠÙ„ PDF", f, "report.pdf")

st.caption("Ø¹Ø±Ø¶ ØªØ¬Ø±ÙŠØ¨ÙŠ â€” ÙŠÙˆØ¶Ø­ Ø§Ù„Ø¥Ù…ÙƒØ§Ù†ÙŠØ§Øª")
